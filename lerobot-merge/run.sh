#!/usr/bin/env bash
set -euo pipefail
IFS=$'\n\t'

# === é…ç½®åŒº ===
INPUT_DIR="${INPUT_DIR:-/inputs}"
OUTPUT_DIR="${OUTPUT_DIR:-/outputs}"
MERGE_SCRIPT="${MERGE_SCRIPT:-}"
DEBUG_SLEEP_SECONDS="${DEBUG_SLEEP_SECONDS:-0}"
TARGET_SCRIPT_NAME="${TARGET_SCRIPT_NAME:-}"
TARGET_SCRIPT_NAMES="${TARGET_SCRIPT_NAMES:-}"
STAGING_MODE="${STAGING_MODE:-copy}"  # copy|symlink ; readonly input should use copy
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

resolve_merge_script() {
    # ä¼˜å…ˆä½¿ç”¨æ˜¾å¼ä¼ å…¥è·¯å¾„
    if [[ -n "$MERGE_SCRIPT" ]]; then
        if [[ -f "$MERGE_SCRIPT" ]]; then
            return 0
        fi
        if [[ -f "$SCRIPT_DIR/$MERGE_SCRIPT" ]]; then
            MERGE_SCRIPT="$SCRIPT_DIR/$MERGE_SCRIPT"
            return 0
        fi
    fi

    # è‡ªåŠ¨æ¢æµ‹å¸¸è§ä½ç½®ï¼ˆå½“å‰ä»“åº“æ˜¯ kuavo ç›®å½•ï¼‰
    if [[ -f "$SCRIPT_DIR/kuavo/merge_data.py" ]]; then
        MERGE_SCRIPT="$SCRIPT_DIR/kuavo/merge_data.py"
        return 0
    fi
    if [[ -f "$SCRIPT_DIR/lerobot_qc/merge_data.py" ]]; then
        MERGE_SCRIPT="$SCRIPT_DIR/lerobot_qc/merge_data.py"
        return 0
    fi

    echo "âŒ æœªæ‰¾åˆ° merge_data.pyï¼Œè¯·è®¾ç½® MERGE_SCRIPTã€‚"
    return 1
}

validate_merged_output() {
    local merged_dir="$1"
    if [[ ! -d "$merged_dir/meta" ]]; then
        echo "âŒ åˆå¹¶ç»“æœç¼ºå¤±ç›®å½•: $merged_dir/meta"
        return 1
    fi
    if [[ ! -f "$merged_dir/meta/info.json" ]]; then
        echo "âŒ åˆå¹¶ç»“æœç¼ºå¤±æ–‡ä»¶: $merged_dir/meta/info.json"
        return 1
    fi
    if [[ ! -d "$merged_dir/data/chunk-000" ]]; then
        echo "âŒ åˆå¹¶ç»“æœç¼ºå¤±ç›®å½•: $merged_dir/data/chunk-000"
        return 1
    fi
    if ! compgen -G "$merged_dir/data/chunk-000/episode_*.parquet" > /dev/null; then
        echo "âŒ åˆå¹¶ç»“æœç¼ºå°‘æ–‡ä»¶: $merged_dir/data/chunk-000/episode_*.parquet"
        return 1
    fi
    return 0
}

# åˆ¤æ–­ä¸€ä¸ªç›®å½•æ˜¯å¦ä¸º LeRobot æ•°æ®é›†ç›®å½•ï¼ˆæœ€å°ç»“æ„æ ¡éªŒï¼‰
is_lerobot_dataset_dir() {
    local dir="$1"
    [[ -d "$dir/meta" ]] \
        && [[ -f "$dir/meta/info.json" ]] \
        && [[ -f "$dir/meta/episodes.jsonl" ]] \
        && [[ -f "$dir/meta/episodes_stats.jsonl" ]] \
        && [[ -f "$dir/meta/tasks.jsonl" ]] \
        && [[ -d "$dir/data/chunk-000" ]] \
        && [[ -d "$dir/videos/chunk-000" ]] \
        && [[ -d "$dir/parameters" ]]
}

# é€’å½’æŸ¥æ‰¾â€œå¯ä½œä¸º merge_data.py --src_dir çš„ç›®å½•â€ï¼š
# å³è¯¥ç›®å½•çš„ä¸€çº§å­ç›®å½•ä¸­ï¼Œè‡³å°‘æœ‰ä¸€ä¸ªæ˜¯æœ‰æ•ˆ LeRobot æ•°æ®é›†
find_merge_sources() {
    local root="$1"
    local candidate_dir child_dir found_valid_child

    while IFS= read -r -d '' candidate_dir; do
        found_valid_child=0
        while IFS= read -r -d '' child_dir; do
            if is_lerobot_dataset_dir "$child_dir"; then
                found_valid_child=1
                break
            fi
        done < <(find "$candidate_dir" -mindepth 1 -maxdepth 1 -type d -print0 2>/dev/null)

        if [[ $found_valid_child -eq 1 ]]; then
            printf '%s\0' "$candidate_dir"
        fi
    done < <(find "$root" -type d -print0 2>/dev/null)
}

# ä»…ä¿ç•™æœ€æ·±å±‚å¯å¤„ç†ç›®å½•ï¼Œé¿å…åŒæ—¶å¤„ç†çˆ¶/å­ç›®å½•å¯¼è‡´ç»“æœå¼‚å¸¸
filter_deepest_sources() {
    local candidates=("$@")
    local i j is_parent
    local deepest=()

    for ((i = 0; i < ${#candidates[@]}; i++)); do
        is_parent=0
        for ((j = 0; j < ${#candidates[@]}; j++)); do
            if [[ $i -ne $j && "${candidates[j]}" == "${candidates[i]}"/* ]]; then
                is_parent=1
                break
            fi
        done
        if [[ $is_parent -eq 0 ]]; then
            deepest+=("${candidates[i]}")
        fi
    done

    if [[ ${#deepest[@]} -gt 0 ]]; then
        printf '%s\0' "${deepest[@]}"
    fi
}

# æŸ¥æ‰¾ source_dir ä¸‹å¯å‚ä¸åˆå¹¶çš„æ•°æ®é›†å­ç›®å½•æ•°é‡ï¼ˆä¸€çº§ï¼‰
count_dataset_children() {
    local source_dir="$1"
    local child_dir count=0
    while IFS= read -r -d '' child_dir; do
        if is_lerobot_dataset_dir "$child_dir"; then
            count=$((count + 1))
        fi
    done < <(find "$source_dir" -mindepth 1 -maxdepth 1 -type d -print0 2>/dev/null)
    echo "$count"
}

print_dataset_issues() {
    local dir="$1"
    local issues=()
    local f

    [[ -d "$dir/meta" ]] || issues+=("ç¼ºå¤±ç›®å½•: meta")
    for f in info.json episodes.jsonl episodes_stats.jsonl tasks.jsonl; do
        [[ -f "$dir/meta/$f" ]] || issues+=("ç¼ºå¤±æ–‡ä»¶: meta/$f")
    done
    for f in episodes.jsonl episodes_stats.jsonl tasks.jsonl; do
        if [[ -f "$dir/meta/$f" ]] && [[ ! -s "$dir/meta/$f" ]]; then
            issues+=("ç©ºæ–‡ä»¶: meta/$f")
        fi
    done

    [[ -d "$dir/data/chunk-000" ]] || issues+=("ç¼ºå¤±ç›®å½•: data/chunk-000")
    compgen -G "$dir/data/chunk-000/episode_*.parquet" > /dev/null || issues+=("ç¼ºå°‘æ–‡ä»¶: data/chunk-000/episode_*.parquet")

    for cam in camera_top camera_wrist_left camera_wrist_right; do
        [[ -d "$dir/videos/chunk-000/observation.images.${cam}" ]] || issues+=("ç¼ºå¤±ç›®å½•: videos/chunk-000/observation.images.${cam}")
        compgen -G "$dir/videos/chunk-000/observation.images.${cam}/episode_*.mp4" > /dev/null || issues+=("ç¼ºå°‘æ–‡ä»¶: videos/chunk-000/observation.images.${cam}/episode_*.mp4")
    done

    [[ -d "$dir/parameters" ]] || issues+=("ç¼ºå¤±ç›®å½•: parameters")
    for f in \
        camera_top_extrinsic.json \
        camera_top_intrinsic.json \
        camera_wrist_left_extrinsic.json \
        camera_wrist_left_intrinsic.json \
        camera_wrist_right_extrinsic.json \
        camera_wrist_right_intrinsic.json; do
        [[ -f "$dir/parameters/$f" ]] || issues+=("ç¼ºå¤±æ–‡ä»¶: parameters/$f")
    done

    if [[ ${#issues[@]} -eq 0 ]]; then
        echo "    âœ… ç»“æ„å®Œæ•´"
    else
        echo "    âŒ ç»“æ„ä¸å®Œæ•´ï¼Œé—®é¢˜æ•°=${#issues[@]}"
        for issue in "${issues[@]}"; do
            echo "      - $issue"
        done
    fi
}

diagnose_source_dir() {
    local source_dir="$1"
    local child_dir
    local child_count=0

    echo "ğŸ”¬ è¯Šæ–­ source_dir: $source_dir"
    while IFS= read -r -d '' child_dir; do
        child_count=$((child_count + 1))
        echo "  [å­ç›®å½• $child_count] $child_dir"
        print_dataset_issues "$child_dir"
    done < <(find "$source_dir" -mindepth 1 -maxdepth 1 -type d -print0 2>/dev/null)

    if [[ $child_count -eq 0 ]]; then
        echo "  âš ï¸ è¯¥ç›®å½•ä¸‹æ²¡æœ‰ä¸€çº§å­ç›®å½•"
    fi
}

# å°†è„šæœ¬åé…ç½®è§£æä¸ºæ•°ç»„ï¼Œæ”¯æŒé€—å·æˆ–ç©ºæ ¼åˆ†éš”
parse_target_scripts() {
    local raw="$1"
    local normalized
    normalized="$(echo "$raw" | tr ',' ' ')"
    read -r -a TARGET_SCRIPTS <<< "$normalized"
}

# åœ¨ /inputs/<data_id>/<script_name> ä¸‹æ”¶é›†éœ€è¦æ£€ç´¢çš„æ ¹ç›®å½•
collect_search_roots() {
    local input_root="$1"
    shift
    local script_names=("$@")
    local data_id_dir script_dir script_name

    while IFS= read -r -d '' data_id_dir; do
        for script_name in "${script_names[@]}"; do
            script_dir="$data_id_dir/$script_name"
            if [[ -d "$script_dir" ]]; then
                printf '%s\0' "$script_dir"
            fi
        done
    done < <(find "$input_root" -mindepth 1 -maxdepth 1 -type d -print0 2>/dev/null)
}

# === ä¸»æµç¨‹ ===
if [[ ! -d "$INPUT_DIR" ]]; then
    echo "âŒ INPUT_DIR ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•: $INPUT_DIR"
    exit 1
fi

# TARGET_SCRIPT_NAME æ˜¯å¹³å°å¼ºçº¦æŸï¼Œä¼˜å…ˆå•å€¼å˜é‡
if [[ -n "$TARGET_SCRIPT_NAME" ]]; then
    TARGET_SCRIPT_NAMES="$TARGET_SCRIPT_NAME"
fi
if [[ -z "${TARGET_SCRIPT_NAMES// }" ]]; then
    echo "âŒ ç¼ºå¤± TARGET_SCRIPT_NAMEï¼ˆæˆ– TARGET_SCRIPT_NAMESï¼‰ã€‚"
    exit 1
fi

if ! resolve_merge_script; then
    exit 1
fi
echo "ğŸ§© ä½¿ç”¨åˆå¹¶è„šæœ¬: $MERGE_SCRIPT"
echo "ğŸ§© staging æ¨¡å¼: $STAGING_MODE"

mkdir -p "$OUTPUT_DIR"
if [[ ! -w "$OUTPUT_DIR" ]]; then
    echo "âŒ OUTPUT_DIR ä¸å¯å†™: $OUTPUT_DIR"
    exit 1
fi

echo "ğŸ” é€’å½’æŸ¥æ‰¾ $INPUT_DIR ä¸‹å¯åˆå¹¶çš„æºç›®å½•..."
echo "ğŸ“ $INPUT_DIR ä¸‹çš„å…¨éƒ¨ç›®å½•åˆ—è¡¨ï¼š"
find "$INPUT_DIR" -type d | sort

if [[ "$DEBUG_SLEEP_SECONDS" =~ ^[0-9]+$ ]] && [[ "$DEBUG_SLEEP_SECONDS" -gt 0 ]]; then
    echo "â¸ï¸ è°ƒè¯•æš‚åœ ${DEBUG_SLEEP_SECONDS} ç§’ï¼ˆçº¦ $((DEBUG_SLEEP_SECONDS / 60)) åˆ†é’Ÿï¼‰ï¼Œå¯è¿›å…¥å®¹å™¨æ£€æŸ¥ç›®å½•ç»“æ„..."
    sleep "$DEBUG_SLEEP_SECONDS"
fi

TARGET_SCRIPTS=()
parse_target_scripts "$TARGET_SCRIPT_NAMES"

search_roots=()
if [[ ${#TARGET_SCRIPTS[@]} -gt 0 ]]; then
    echo "ğŸ¯ é™å®šè„šæœ¬ç›®å½•: ${TARGET_SCRIPTS[*]}"
    mapfile -d '' -t search_roots < <(collect_search_roots "$INPUT_DIR" "${TARGET_SCRIPTS[@]}" | sort -z)
    if [[ ${#search_roots[@]} -eq 0 ]]; then
        echo "âŒ æœªæ‰¾åˆ°æŒ‡å®šè„šæœ¬ç›®å½•: ${TARGET_SCRIPTS[*]}"
        exit 1
    fi
else
    search_roots=("$INPUT_DIR")
fi

echo "ğŸ” å®é™…æ£€ç´¢æ ¹ç›®å½•æ•°é‡: ${#search_roots[@]}"
for r in "${search_roots[@]}"; do
    echo "  - $r"
done

all_source_dirs=()
for root in "${search_roots[@]}"; do
    mapfile -d '' -t root_sources < <(find_merge_sources "$root" | sort -z)
    all_source_dirs+=("${root_sources[@]}")
done
if [[ ${#all_source_dirs[@]} -gt 0 ]]; then
    mapfile -d '' -t all_source_dirs < <(printf '%s\0' "${all_source_dirs[@]}" | sort -zu)
else
    all_source_dirs=()
fi

mapfile -d '' -t source_dirs < <(filter_deepest_sources "${all_source_dirs[@]}" | sort -z)

# å…œåº•ç§»é™¤ç©ºè·¯å¾„ï¼Œé¿å…ç©ºå…ƒç´ è¢«å½“æˆä¸€ä¸ªç›®å½•
valid_source_dirs=()
for source_dir in "${source_dirs[@]}"; do
    if [[ -n "$source_dir" ]]; then
        valid_source_dirs+=("$source_dir")
    fi
done
source_dirs=("${valid_source_dirs[@]}")

if [ ${#source_dirs[@]} -eq 0 ]; then
    echo "âŒ æœªæ‰¾åˆ°å¯å¤„ç†ç›®å½•ã€‚è¯·ç¡®è®¤ç›®å½•ä¸­å­˜åœ¨æ ‡å‡† LeRobot æ•°æ®é›†ç»“æ„ã€‚"
    exit 1
fi

echo "âœ… æ‰¾åˆ° ${#source_dirs[@]} ä¸ªå¯å¤„ç†ç›®å½•ã€‚"
for s in "${source_dirs[@]}"; do
    echo "  - $s"
done

all_dataset_dirs=()
for source_dir in "${source_dirs[@]}"; do
    dataset_count="$(count_dataset_children "$source_dir")"
    diagnose_source_dir "$source_dir"
    if [[ "$dataset_count" -eq 0 ]]; then
        echo "âš ï¸ è·³è¿‡ç›®å½•ï¼ˆæ— æœ‰æ•ˆæ•°æ®é›†å­ç›®å½•ï¼‰: $source_dir"
        continue
    fi
    while IFS= read -r -d '' child_dir; do
        if is_lerobot_dataset_dir "$child_dir"; then
            all_dataset_dirs+=("$child_dir")
        fi
    done < <(find "$source_dir" -mindepth 1 -maxdepth 1 -type d -print0 2>/dev/null)
done

if [[ ${#all_dataset_dirs[@]} -eq 0 ]]; then
    echo "âŒ æ²¡æœ‰å¯ç”¨äºå…¨å±€åˆå¹¶çš„ LeRobot æ•°æ®é›†å­ç›®å½•ã€‚"
    exit 1
fi

mapfile -d '' -t all_dataset_dirs < <(printf '%s\0' "${all_dataset_dirs[@]}" | sort -zu)
echo "ğŸ“¦ æ”¶é›†åˆ° ${#all_dataset_dirs[@]} ä¸ªæ•°æ®é›†å­ç›®å½•ï¼Œå°†æ‰§è¡Œä¸€æ¬¡å…¨å±€åˆå¹¶ã€‚"
for d in "${all_dataset_dirs[@]}"; do
    echo "  - $d"
done

staging_dir="$(mktemp -d /tmp/lerobot_merge_staging.XXXXXX)"
cleanup_staging() {
    chmod -R u+w "$staging_dir" 2>/dev/null || true
    rm -rf "$staging_dir"
}
trap cleanup_staging EXIT

idx=1
for d in "${all_dataset_dirs[@]}"; do
    target="$staging_dir/dataset_$(printf '%04d' "$idx")"
    if [[ "$STAGING_MODE" == "symlink" ]]; then
        ln -s "$d" "$target"
    else
        cp -a "$d" "$target"
        chmod -R u+w "$target" 2>/dev/null || true
    fi
    idx=$((idx + 1))
done

merged_dir="$OUTPUT_DIR/lerobot_merged"
echo "========== å…¨å±€åˆå¹¶ =========="
echo "æ±‡æ€»ç›®å½•: $staging_dir"
echo "è¾“å‡ºç›®å½•: $merged_dir"

rm -rf "$merged_dir"
mkdir -p "$(dirname "$merged_dir")"

if python3 "$MERGE_SCRIPT" \
    --src_dir "$staging_dir" \
    --tgt_dir "$merged_dir" \
    --save; then
    if validate_merged_output "$merged_dir"; then
        echo "âœ… å…¨å±€åˆå¹¶å®Œæˆ: $merged_dir"
    else
        echo "âŒ åˆå¹¶ç»“æœæ ¡éªŒå¤±è´¥ã€‚"
        exit 1
    fi
else
    echo "âŒ å…¨å±€åˆå¹¶å¤±è´¥ã€‚"
    exit 1
fi

echo "ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼Œè¾“å‡ºç›®å½•: $merged_dir"
