"""Post-processing utilities for torque/current conversion and HDF5 export."""

import os

import numpy as np

class PostProcessorUtils:
    @staticmethod
    def torque_to_current_batch(
        torque_data: np.ndarray,
        MOTOR_C2T=[
            2,
            1.05,
            1.05,
            2,
            2.1,
            2.1,
            2,
            1.05,
            1.05,
            2,
            2.1,
            2.1,
            1.05,
            5,
            2.3,
            5,
            4.7,
            4.7,
            4.7,
            1.05,
            5,
            2.3,
            5,
            4.7,
            4.7,
            4.7,
            0.21,
            4.7,
        ],
    ):
        """
        å°†æ‰­çŸ©æ•°æ®æ‰¹é‡è½¬æ¢ä¸ºç”µæµæ•°æ®

        Args:
            torque_data: æ‰­çŸ©æ•°æ®æ•°ç»„(N, M)
            MOTOR_C2T: ç”µæµè½¬æ‰­çŸ©ç³»æ•°æ•°ç»„ï¼Œé»˜è®¤å€¼ä¸º kuavo-ros-control ä¸­å®šä¹‰çš„ç³»æ•°
        Returns:
            ç”µæµæ•°æ®æ•°ç»„
        """
        if torque_data.shape[1] != len(MOTOR_C2T):
            print(
                f"è­¦å‘Š: æ‰­çŸ©æ•°æ®é•¿åº¦({torque_data.shape[1]})ä¸C2Tç³»æ•°æ•°é‡({len(MOTOR_C2T)})ä¸åŒ¹é…"
            )
            return None

        # å¤åˆ¶æ•°æ®é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        current_data = torque_data.copy()

        from itertools import chain

        # 13~18 ä¸ºå·¦è‡‚ruiwoç”µæœºæ•°æ®, 20~27 ä¸ºå³è‡‚ruiwoç”µæœºæ•°æ®
        # å¯¹äºè¿™äº›ç”µæœºéœ€è¦å…ˆé™¤ä»¥MOTOR_C2Tç³»æ•°å†ä¹˜ä»¥2.1
        for i in chain(range(13, 19), range(20, 28)):  # ä¿®æ­£ä¸º27+1=28
            current_data[:, i] = (torque_data[:, i] / MOTOR_C2T[i]) * 2.1

        # 1, 2, 7, 8, 12, 19 å·ç”µæœºéœ€è¦ç‰¹æ®Šå¤„ç†
        for i in [1, 2, 7, 8, 12, 19]:
            current_data[:, i] = (torque_data[:, i] / MOTOR_C2T[i]) * 1.2

        # å…¶ä»–ç”µæœºï¼šECç”µæœºï¼Œç›´æ¥é™¤ä»¥MOTOR_C2Tç³»æ•°
        other_indices = [
            i
            for i in range(len(MOTOR_C2T))
            if i not in chain(range(13, 19), range(20, 28), [1, 2, 7, 8, 12, 19])
        ]
        for i in other_indices:
            current_data[:, i] = torque_data[:, i] / MOTOR_C2T[i]

        return current_data

    @staticmethod
    def current_to_torque(
        current_data: np.ndarray,
        MOTOR_C2T=[
            2,
            1.05,
            1.05,
            2,
            2.1,
            2.1,
            2,
            1.05,
            1.05,
            2,
            2.1,
            2.1,
            1.05,
            5,
            2.3,
            5,
            4.7,
            4.7,
            4.7,
            1.05,
            5,
            2.3,
            5,
            4.7,
            4.7,
            4.7,
            0.21,
            4.7,
        ],
    ):
        """
        å°† sensors_data_raw ä¸­çš„ joint_torque ç”µæµæ•°æ®è½¬æ¢ä¸ºæ‰­çŸ©æ•°æ®

        Args:
            current_data: ç”µæµæ•°æ®æ•°ç»„(N, 28)
            MOTOR_C2T: ç”µæµè½¬æ‰­çŸ©ç³»æ•°æ•°ç»„ï¼Œé»˜è®¤å€¼ä¸º kuavo-ros-control ä¸­å®šä¹‰çš„ç³»æ•°
        Returns:
            æ‰­çŸ©æ•°æ®æ•°ç»„
        """
        if len(current_data) != len(MOTOR_C2T):
            print(
                f"è­¦å‘Š: ç”µæµæ•°æ®é•¿åº¦({len(current_data)})ä¸C2Tç³»æ•°æ•°é‡({len(MOTOR_C2T)})ä¸åŒ¹é…"
            )
            # æ‰©å±•æˆ–æˆªæ–­ç³»æ•°æ•°ç»„
            return None

        torque_data = []
        # "MOTORS_TYPE":[
        # "PA100_18", "PA100", "PA100", "PA100_18", "CK", "CK",
        # "PA100_18", "PA100", "PA100", "PA100_18", "CK", "CK",
        # "PA100", "ruiwo", "ruiwo", "ruiwo", "ruiwo", "ruiwo", "ruiwo",
        # "PA100", "ruiwo", "ruiwo", "ruiwo", "ruiwo", "ruiwo", "ruiwo", "ruiwo", "ruiwo"],

        for i, current in enumerate(current_data):
            # kuavo-ros-control/src/kuavo_common/include/kuavo_common/common/kuavo_settings.h
            # ä¸­å®šä¹‰äº† ruiwo ç”µæœºç”µæµè½¬æ‰­çŸ©ç³»æ•° CK_C2T = 2.1ï¼Œæ‰€ä»¥è¿™é‡Œé™¤ä»¥ 2.1 è½¬åŒ–å›åŸå§‹ç”µæµ

            # 13~18 ä¸ºå·¦è‡‚ruiwoç”µæœºæ•°æ®, 20~25 ä¸ºå³è‡‚ruiwoç”µæœºæ•°æ®
            # å¯¹äºè¿™äº›ç”µæœºéœ€è¦å…ˆé™¤ä»¥2.1è½¬æ¢å›åŸå§‹ç”µæµ
            if 13 <= i <= 18 or 20 <= i <= 27:
                torque = (current / 2.1) * MOTOR_C2T[i]
            elif i == 1 or i == 2 or i == 7 or i == 8 or i == 12 or i == 19:
                torque = (current / 1.2) * MOTOR_C2T[i]
            else:

                # EC ç”µæœº sensors_data_raw ä¸­å·²ç»æ˜¯æ‰­çŸ©å€¼
                torque = current
            torque_data.append(torque)

        return np.array(torque_data)

    @staticmethod
    def current_to_torque_batch(
        current_data: np.ndarray,
        MOTOR_C2T=[
            2,
            1.05,
            1.05,
            2,
            2.1,
            2.1,
            2,
            1.05,
            1.05,
            2,
            2.1,
            2.1,
            1.05,
            5,
            2.3,
            5,
            4.7,
            4.7,
            4.7,
            1.05,
            5,
            2.3,
            5,
            4.7,
            4.7,
            4.7,
            0.21,
            4.7,
        ],
    ):
        """
        å°† sensors_data_raw ä¸­çš„ joint_torque ç”µæµæ•°æ®è½¬æ¢ä¸ºæ‰­çŸ©æ•°æ®

        Args:
            current_data: ç”µæµæ•°æ®æ•°ç»„(N, M)
            MOTOR_C2T: ç”µæµè½¬æ‰­çŸ©ç³»æ•°æ•°ç»„ï¼Œé»˜è®¤å€¼ä¸º kuavo-ros-control ä¸­å®šä¹‰çš„ç³»æ•°
        Returns:
            æ‰­çŸ©æ•°æ®æ•°ç»„
        """

        if current_data.shape[1] != len(MOTOR_C2T):
            print(
                f"è­¦å‘Š: ç”µæµæ•°æ®é•¿åº¦({current_data.shape[1]})ä¸C2Tç³»æ•°æ•°é‡({len(MOTOR_C2T)})ä¸åŒ¹é…"
            )
            # æ‰©å±•æˆ–æˆªæ–­ç³»æ•°æ•°ç»„
            return None

        from itertools import chain

        for i in chain(range(13, 19), range(20, 28)):
            current_data[:, i] = current_data[:, i] / 2.1 * MOTOR_C2T[i]
        for i in [1, 2, 7, 8, 12, 19]:
            current_data[:, i] = current_data[:, i] / 1.2 * MOTOR_C2T[i]
        # å¯¹äºå…¶ä»–ç”µæœºç›´æ¥ä½¿ç”¨åŸå§‹ç”µæµ
        # EC ç”µæœº sensors_data_raw ä¸­å·²ç»æ˜¯æ‰­çŸ©å€¼
        return current_data

    @staticmethod
    def save_to_hdf5(low_dim_data, file_path):
        """å°†æ•°æ®ä¿å­˜ä¸ºç¬¦åˆåº“å¸•æ€é€šç”¨ç‰ˆæ•°æ®æ ¼å¼çš„HDF5æ–‡ä»¶"""
        import h5py

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(file_path), exist_ok=True)

        def create_datasets_recursively(group, data_dict, current_path=""):
            """é€’å½’åˆ›å»ºæ•°æ®é›†å’Œç»„"""
            for key, value in data_dict.items():
                full_path = f"{current_path}/{key}" if current_path else key

                if isinstance(value, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œåˆ›å»ºå­ç»„å¹¶é€’å½’å¤„ç†
                    subgroup = group.create_group(key)
                    create_datasets_recursively(subgroup, value, full_path)
                else:
                    # å¦‚æœæ˜¯æ•°æ®ï¼Œåˆ›å»ºæ•°æ®é›†
                    try:
                        # å¤„ç†ä¸åŒç±»å‹çš„æ•°æ®
                        if isinstance(value, (list, tuple)):
                            value = np.array(value)

                        # æ ¹æ®æ•°æ®ç±»å‹å’Œè·¯å¾„è¿›è¡Œç‰¹æ®Šå¤„ç†
                        processed_value = process_data_by_path(value, full_path)

                        # åˆ›å»ºæ•°æ®é›†
                        group.create_dataset(key, data=processed_value)
                        print(
                            f"åˆ›å»ºæ•°æ®é›†: {full_path}, å½¢çŠ¶: {processed_value.shape}, ç±»å‹: {processed_value.dtype}"
                        )

                    except Exception as e:
                        print(f"è­¦å‘Š: æ— æ³•åˆ›å»ºæ•°æ®é›† {full_path}: {e}")
                        # åˆ›å»ºç©ºæ•°æ®é›†ä½œä¸ºå ä½ç¬¦
                        try:
                            empty_data = np.array([])
                            group.create_dataset(key, data=empty_data)
                        except:
                            pass

        def process_data_by_path(value, path):
            """æ ¹æ®æ•°æ®è·¯å¾„å¯¹æ•°æ®è¿›è¡Œç‰¹æ®Šå¤„ç†"""
            # æ—¶é—´æˆ³å¤„ç† - æ‰©å±•è¯†åˆ«æ–°çš„æ—¶é—´æˆ³å­—æ®µ
            timestamp_fields = [
                "timestamps",
                "head_color_mp4_camera_timestamps",
                "hand_left_color_mp4_timestamps",
                "hand_right_color_mp4_timestamps",
                "head_depth_mkv_camera_timestamps",
                "hand_left_depth_mkv_timestamps",
                "hand_right_depth_mkv_timestamps",
                "camera_extrinsics_timestamps",
                "head_timestamps" "joint_timestamps",
                "effector_dexhand_timestamps",
                "effector_lejuclaw_timestamps",
            ]

            if any(ts_field in path for ts_field in timestamp_fields):
                if value.dtype != np.int64:
                    # è½¬æ¢æ—¶é—´æˆ³ä¸ºçº³ç§’çº§æ•´æ•°
                    if np.issubdtype(value.dtype, np.floating):
                        return (value * 1e9).astype(np.int64)
                    else:
                        return value.astype(np.int64)
                return value

            # ç´¢å¼•æ•°æ®å¤„ç†
            elif "index" in path:
                return value.astype(np.int64)

            # å…¶ä»–æ•°å€¼æ•°æ®å¤„ç†
            elif np.issubdtype(value.dtype, np.number):
                # æ ¹æ®æ•°æ®ç±»å‹å†³å®šç²¾åº¦
                if np.issubdtype(value.dtype, np.integer):
                    return value.astype(np.int32)
                else:
                    return value.astype(np.float32)

            # ä¿æŒåŸå§‹æ•°æ®ç±»å‹
            return value

        def add_missing_required_fields(f, low_dim_data):
            """æ·»åŠ åº“å¸•æ€æ ¼å¼ä¸­å¿…éœ€ä½†ç¼ºå¤±çš„å­—æ®µï¼Œä½¿ç”¨nullæœºåˆ¶"""

            # è·å–æ—¶é—´æˆ³é•¿åº¦ä½œä¸ºå‚è€ƒ
            if "timestamps" in low_dim_data:
                N = len(low_dim_data["timestamps"])
            else:
                N = 1000  # é»˜è®¤å€¼
                for key, value in low_dim_data.items():
                    if hasattr(value, "__len__") and not isinstance(value, str):
                        N = len(value)
                        break

            # åˆ›å»ºæ§åˆ¶ç´¢å¼•
            control_indices = np.arange(N, dtype=np.int64)

            def create_null_dataset(group, name, shape, dtype):
                """åˆ›å»ºä¸€ä¸ªè¡¨ç¤ºç¼ºå¤±æ•°æ®çš„æ•°æ®é›†"""
                # æ–¹æ³•1: ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±æ•°æ®ï¼ˆä»…é€‚ç”¨äºæµ®ç‚¹æ•°ï¼‰
                if dtype == np.float32æˆ–dtype == np.float64:
                    data = np.full(shape, np.nan, dtype=dtype)
                    dataset = group.create_dataset(name, data=data)
                    # æ·»åŠ å±æ€§æ ‡è®°è¿™æ˜¯ç¼ºå¤±æ•°æ®
                    dataset.attrs["missing_data"] = True
                    dataset.attrs["description"] = f"Missing data filled with NaN"
                    return dataset

                # æ–¹æ³•2: åˆ›å»ºç©ºæ•°æ®é›†ï¼ˆå¯¹äºæ•´æ•°ç±»å‹ï¼‰
                elif np.issubdtype(dtype, np.integer):
                    # å¯¹äºæ•´æ•°ï¼Œä½¿ç”¨æœ€å°å€¼è¡¨ç¤ºç¼ºå¤±
                    if dtype == np.int32:
                        fill_value = np.iinfo(np.int32).min
                    elif dtype == np.int64:
                        fill_value = np.iinfo(np.int64).min
                    else:
                        fill_value = -999999  # é»˜è®¤ç¼ºå¤±å€¼

                    data = np.full(shape, fill_value, dtype=dtype)
                    dataset = group.create_dataset(name, data=data)
                    dataset.attrs["missing_data"] = True
                    dataset.attrs["fill_value"] = fill_value
                    dataset.attrs["description"] = (
                        f"Missing data filled with {fill_value}"
                    )
                    return dataset

                # æ–¹æ³•3: ä¸åˆ›å»ºæ•°æ®é›†ï¼Œä»…æ·»åŠ å ä½ç¬¦å±æ€§
                else:
                    # åˆ›å»ºä¸€ä¸ªåªæœ‰å±æ€§çš„ç»„æ¥è¡¨ç¤ºç¼ºå¤±
                    missing_group = group.create_group(name + "_missing")
                    missing_group.attrs["missing_data"] = True
                    missing_group.attrs["expected_shape"] = shape
                    missing_group.attrs["expected_dtype"] = str(dtype)
                    missing_group.attrs["description"] = (
                        "Data not available - missing field"
                    )
                    return missing_group

            def create_optional_dataset(
                group, name, shape, dtype, description="Optional field not available"
            ):
                """åˆ›å»ºå¯é€‰çš„æ•°æ®é›†ï¼Œæ˜ç¡®æ ‡è®°ä¸ºä¸å¯ç”¨"""
                # æ–¹æ³•4: åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†ï¼Œé•¿åº¦ä¸º0
                empty_data = np.array([], dtype=dtype)
                dataset = group.create_dataset(name, data=empty_data, maxshape=shape)
                dataset.attrs["data_available"] = False
                dataset.attrs["expected_shape"] = shape
                dataset.attrs["description"] = description
                return dataset

            # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„ action ç»„å­—æ®µ
            if "action" in f:
                action_group = f["action"]

                # # æ·»åŠ ç¼ºå¤±çš„ robot ç»„
                # if "robot" not in action_group:
                #     robot_group = action_group.create_group("robot")
                #     create_null_dataset(robot_group, "velocity", (N, 2), np.float32)
                #     create_null_dataset(robot_group, "index", (N,), np.float32)
                #     print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: action/robot (ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±)")

                # # æ·»åŠ ç¼ºå¤±çš„ waist ç»„
                # if "waist" not in action_group:
                #     waist_group = action_group.create_group("waist")
                #     create_null_dataset(waist_group, "position", (N, 2), np.float32)
                #     create_null_dataset(waist_group, "index", (N,), np.float32)
                #     print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: action/waist (ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±)")

                # # æ·»åŠ ç¼ºå¤±çš„ end ç»„
                # if "end" not in action_group:
                #     end_group = action_group.create_group("end")
                #     create_null_dataset(end_group, "orientation", (N, 2, 4), np.float32)
                #     create_null_dataset(end_group, "position", (N, 2, 3), np.float32)
                #     create_null_dataset(end_group, "index", (N,), np.float32)
                #     print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: action/end (ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±)")

            # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„ state ç»„å­—æ®µ
            if "state" in f:
                state_group = f["state"]

                # # æ·»åŠ ç¼ºå¤±çš„ end ç»„
                # if "end" not in state_group:
                #     end_group = state_group.create_group("end")
                #     create_null_dataset(end_group, "angular", (N, 2, 3), np.float32)
                #     create_null_dataset(end_group, "orientation", (N, 2, 4), np.float32)
                #     create_null_dataset(end_group, "position", (N, 2, 3), np.float32)
                #     create_null_dataset(end_group, "velocity", (N, 2, 3), np.float32)
                #     create_null_dataset(end_group, "wrench", (N, 2, 6), np.float32)
                #     print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: state/end (ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±)")

                # æ·»åŠ ç¼ºå¤±çš„ robot ç»„
                if "robot" not in state_group:
                    robot_group = state_group.create_group("robot")

                    # å¯¹äºæœºå™¨äººå§¿æ€ï¼Œå¦‚æœæ²¡æœ‰IMUæ•°æ®ï¼Œæ˜ç¡®æ ‡è®°ä¸ºç¼ºå¤±
                    if "imu" in low_dim_data and "quat_xyzw" in low_dim_data["imu"]:
                        imu_data_quat_xyzw = low_dim_data["imu"]["quat_xyzw"]
                        if (
                            hasattr(imu_data_quat_xyzw, "shape")
                            and len(imu_data_quat_xyzw.shape) > 1
                            and imu_data_quat_xyzw.shape[1] >= 4
                        ):
                            # æœ‰IMUæ•°æ®ï¼Œç›´æ¥ä½¿ç”¨
                            orientation = np.zeros((N, 4), dtype=np.float32)
                            orientation[:, :] = imu_data_quat_xyzw
                            dataset = robot_group.create_dataset(
                                "orientation", data=orientation
                            )
                            dataset.attrs["data_source"] = "IMU sensor"
                            dataset.attrs["missing_data"] = False
                            print(f"ä»IMUæ•°æ®æå–æœºå™¨äººå§¿æ€")
                        else:
                            # IMUæ•°æ®æ ¼å¼ä¸å¯¹ï¼Œæ ‡è®°ä¸ºç¼ºå¤±
                            create_null_dataset(
                                robot_group, "orientation", (N, 4), np.float32
                            )
                            print(f"IMUæ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œå§¿æ€æ•°æ®æ ‡è®°ä¸ºç¼ºå¤±")
                    else:
                        # æ²¡æœ‰IMUæ•°æ®ï¼Œæ ‡è®°ä¸ºç¼ºå¤±
                        create_null_dataset(
                            robot_group, "orientation", (N, 4), np.float32
                        )
                        print(f"æ— IMUæ•°æ®ï¼Œå§¿æ€æ•°æ®æ ‡è®°ä¸ºç¼ºå¤±")

                    # å…¶ä»–æœºå™¨äººçŠ¶æ€æ ‡è®°ä¸ºç¼ºå¤±
                    # create_null_dataset(robot_group, "orientation_drift", (N, 4), np.float32)
                    # create_null_dataset(robot_group, "position", (N, 3), np.float32)
                    # create_null_dataset(robot_group, "position_drift", (N, 3), np.float32)
                    print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: state/robot (ä½¿ç”¨NaN/ç¼ºå¤±å€¼è¡¨ç¤º)")

                # # æ·»åŠ ç¼ºå¤±çš„ waist ç»„
                # if "waist" not in state_group:
                #     waist_group = state_group.create_group("waist")
                #     create_null_dataset(waist_group, "effort", (N, 2), np.float32)
                #     create_null_dataset(waist_group, "position", (N, 2), np.float32)
                #     create_null_dataset(waist_group, "velocity", (N, 2), np.float32)
                #     print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: state/waist (ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±)")

                # ä¸ºç°æœ‰ç»„æ·»åŠ ç¼ºå¤±çš„æ•°æ®é›†
                # if "effector" in state_group:
                #     effector_group = state_group["effector"]
                #     if "force" not in effector_group:
                #         create_null_dataset(effector_group, "force", (N, 2), np.float32)
                #         print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: state/effector/force (ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±)")

                if "head" in state_group:
                    head_group = state_group["head"]
                    if "effort" not in head_group:
                        create_null_dataset(head_group, "effort", (N, 2), np.float32)
                        print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: state/head/effort (ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±)")

                if "joint" in state_group:
                    joint_group = state_group["joint"]
                    # è·å–å…³èŠ‚æ•°é‡
                    joint_count = 14  # é»˜è®¤å€¼
                    if "position" in joint_group:
                        joint_count = joint_group["position"].shape[1]
                    elif "velocity" in joint_group:
                        joint_count = joint_group["velocity"].shape[1]

                    if "current_value" not in joint_group:
                        create_null_dataset(
                            joint_group, "current_value", (N, joint_count), np.float32
                        )
                        print(
                            f"æ·»åŠ ç¼ºå¤±å­—æ®µ: state/joint/current_value (ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±)"
                        )

                    if "effort" not in joint_group:
                        create_null_dataset(
                            joint_group, "effort", (N, joint_count), np.float32
                        )
                        print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: state/joint/effort (ä½¿ç”¨NaNè¡¨ç¤ºç¼ºå¤±)")

            # æ·»åŠ  other_sensors ç»„ï¼ˆæ ‡è®°ä¸ºå¯é€‰ï¼‰
            # if "other_sensors" not in f:
            #     other_group = f.create_group("other_sensors")
            #     other_group.attrs['description'] = 'Optional sensor data - currently empty'
            #     other_group.attrs['data_available'] = False
            #     print(f"æ·»åŠ ç¼ºå¤±å­—æ®µ: other_sensors (æ ‡è®°ä¸ºå¯é€‰æ•°æ®)")
            # æ–°å¢ï¼šåœ¨æ ¹çº§åˆ«æ·»åŠ æ—¶é—´æˆ³å­—æ®µçš„å­˜åœ¨æ€§ä¿¡æ¯

        # åˆ›å»º HDF5 æ–‡ä»¶
        with h5py.File(file_path, "w") as f:
            print(f"å¼€å§‹åˆ›å»ºHDF5æ–‡ä»¶: {file_path}")

            # é€’å½’åˆ›å»ºæ‰€æœ‰æ•°æ®é›†å’Œç»„
            create_datasets_recursively(f, low_dim_data)

            # æ·»åŠ åº“å¸•æ€æ ¼å¼è¦æ±‚çš„ç¼ºå¤±å­—æ®µå¡«å……ä¸ºNaNæˆ–ç¼ºå¤±å€¼
            add_missing_required_fields(f, low_dim_data)

        print(f"æ•°æ®å·²æˆåŠŸä¿å­˜ä¸ºHDF5æ ¼å¼: {file_path}")
        return file_path


if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    print("åˆ›å»ºæµ‹è¯•å®ä¾‹...")

    # æ¨¡æ‹Ÿé…ç½®
    class TestConfig:
        def __init__(self):
            self.default_camera_names = ["head_cam_h"]
            self.train_hz = 30
            self.main_timeline_fps = 30
            self.sample_drop = 0
            self.resize = type("obj", (object,), {"width": 640, "height": 480})()
            self.topics = []
            self.eef_type = "dexhand"

    config = TestConfig()
    reader = KuavoRosbagReader(config)

    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼šæ¨¡æ‹Ÿå‰ç½®æ­¥éª¤å¤„ç†åçš„æ•°æ®ç‰¹å¾
    # - æ‰€æœ‰é—´éš”éƒ½å°äº40ms
    # - æ€»å¸§ç‡çº¦32Hzï¼ˆéœ€è¦åˆ é™¤å¸§é™åˆ°30Hzï¼‰
    print("åˆ›å»ºæµ‹è¯•æ•°æ®...")

    # ç”Ÿæˆ32Hzçš„åŸºæœ¬æ—¶é—´æˆ³åºåˆ—
    base_interval = 1.0 / 32.0  # 32Hz = 31.25msé—´éš”
    total_frames = 800  # è¶³å¤Ÿé•¿çš„æ•°æ®
    total_duration = total_frames * base_interval  # æ€»æ—¶é•¿

    # åˆ›å»ºå‡åŒ€çš„32Hzæ—¶é—´æˆ³ä½œä¸ºåŸºç¡€
    uniform_timestamps = np.linspace(1.0, 1.0 + total_duration, total_frames)

    # æ·»åŠ ä¸€äº›éšæœºæ€§ï¼Œä½†ç¡®ä¿é—´éš”å§‹ç»ˆ<40ms
    timestamps = []
    for i in range(total_frames):
        base_ts = uniform_timestamps[i]

        if i == 0:
            # ç¬¬ä¸€å¸§ä¿æŒä¸å˜
            timestamps.append(base_ts)
        else:
            # æ·»åŠ éšæœºåç§»ï¼Œä½†ç¡®ä¿ä¸å‰ä¸€å¸§çš„é—´éš”åœ¨15-38msä¹‹é—´
            prev_ts = timestamps[-1]
            min_interval = 0.015  # 15ms
            max_interval = 0.038  # 38ms

            # è®¡ç®—ç†æƒ³çš„ä¸‹ä¸€ä¸ªæ—¶é—´æˆ³
            ideal_next = prev_ts + base_interval

            # æ·»åŠ éšæœºåç§»ï¼Œä½†é™åˆ¶åœ¨å®‰å…¨èŒƒå›´å†…
            random_offset = np.random.uniform(-0.008, 0.008)  # Â±8mséšæœºåç§»
            candidate_ts = ideal_next + random_offset

            # ç¡®ä¿é—´éš”åœ¨å®‰å…¨èŒƒå›´å†…
            actual_interval = candidate_ts - prev_ts
            if actual_interval < min_interval:
                candidate_ts = prev_ts + min_interval
            elif actual_interval > max_interval:
                candidate_ts = prev_ts + max_interval

            timestamps.append(candidate_ts)

    main_timestamps = np.array(timestamps)

    # éªŒè¯ç”Ÿæˆçš„æ—¶é—´æˆ³è´¨é‡
    intervals_ms = np.diff(main_timestamps) * 1000
    max_interval_ms = np.max(intervals_ms)
    min_interval_ms = np.min(intervals_ms)
    avg_interval_ms = np.mean(intervals_ms)

    # ç¡®ä¿æ‰€æœ‰é—´éš”éƒ½å°äº40ms
    assert (
        max_interval_ms < 40.0
    ), f"ç”Ÿæˆçš„æœ€å¤§é—´éš” {max_interval_ms:.1f}ms è¶…è¿‡40msé™åˆ¶"

    # å­æ—¶é—´æˆ³ï¼šæ¯”ä¸»æ—¶é—´æˆ³æ™š2ms
    child_timestamps = main_timestamps + 0.002

    # åˆ›å»ºå¯¹åº”çš„æ•°æ®
    valid_modalities = {
        "head_cam_h": [
            {"timestamp": ts, "data": f"main_frame_{i}", "frame_id": i}
            for i, ts in enumerate(main_timestamps)
        ],
        "child_sensor": [
            {"timestamp": ts, "data": f"child_data_{i}", "sensor_value": i * 10}
            for i, ts in enumerate(child_timestamps)
        ],
    }

    # è®¡ç®—åˆå§‹å¸§ç‡
    time_span = main_timestamps[-1] - main_timestamps[0]
    initial_fps = len(main_timestamps) / time_span
    target_fps = 30.095

    print(f"æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ:")
    print(f"  ä¸»æ—¶é—´æˆ³é•¿åº¦: {len(main_timestamps)}")
    print(f"  æ—¶é—´è·¨åº¦: {time_span:.3f}s")
    print(f"  åˆå§‹å¸§ç‡: {initial_fps:.2f}Hz")
    print(f"  ç›®æ ‡å¸§ç‡: {target_fps:.2f}Hz")
    print(f"  éœ€è¦åˆ é™¤çº¦ {len(main_timestamps) - int(time_span * target_fps)} å¸§")

    print(f"  æ—¶é—´é—´éš”ç»Ÿè®¡:")
    print(f"    å¹³å‡é—´éš”: {avg_interval_ms:.1f}ms")
    print(f"    æœ€å¤§é—´éš”: {max_interval_ms:.1f}ms")
    print(f"    æœ€å°é—´éš”: {min_interval_ms:.1f}ms")
    print(f"    âœ“ æ‰€æœ‰é—´éš”éƒ½åœ¨40msä»¥å†…ï¼ˆæ¨¡æ‹Ÿå‰ç½®å¤„ç†å®Œæˆï¼‰")

    # éªŒè¯å¸§ç‡åˆç†æ€§
    if 31.5 <= initial_fps <= 33.0:
        print(f"    âœ“ åˆå§‹å¸§ç‡ {initial_fps:.2f}Hz åœ¨æœŸæœ›èŒƒå›´å†…ï¼ˆ31.5-33Hzï¼‰")
    else:
        print(f"    âš ï¸ åˆå§‹å¸§ç‡ {initial_fps:.2f}Hz ä¸åœ¨æœŸæœ›èŒƒå›´å†…")

    print("\nåˆå§‹æ•°æ®æ ·æœ¬ï¼ˆå‰10å¸§ï¼‰:")
    print("ä¸»æ—¶é—´æˆ³:")
    for i in range(min(10, len(main_timestamps))):
        interval_ms = 0
        if i > 0:
            interval_ms = (main_timestamps[i] - main_timestamps[i - 1]) * 1000
        print(f"  å¸§{i}: {main_timestamps[i]:.6f}s (é—´éš”: {interval_ms:.1f}ms)")

    print("\nå­æ—¶é—´æˆ³æ ·æœ¬ï¼ˆå‰5å¸§ï¼‰:")
    for i in range(min(5, len(valid_modalities["child_sensor"]))):
        item = valid_modalities["child_sensor"][i]
        main_ts = main_timestamps[i]
        diff_ms = (item["timestamp"] - main_ts) * 1000
        print(
            f"  å¸§{i}: {item['timestamp']:.6f}s (ä¸ä¸»æ—¶é—´æˆ³å·®: {diff_ms:.1f}ms, æ•°æ®: {item['data']})"
        )

    print("\nå¼€å§‹æµ‹è¯• _remove_frames_to_decrease_fps...")
    print("=" * 60)

    try:
        # è°ƒç”¨å‡½æ•°è¿›è¡Œæµ‹è¯•
        result_timestamps, result_modalities = reader._remove_frames_to_decrease_fps(
            main_timestamps.copy(),  # ä½¿ç”¨å‰¯æœ¬é¿å…ä¿®æ”¹åŸæ•°æ®
            {k: list(v) for k, v in valid_modalities.items()},  # æ·±æ‹·è´
            target_fps,
            time_span,
        )

        print("=" * 60)
        print("æµ‹è¯•å®Œæˆ!")

        # éªŒè¯ç»“æœ
        final_time_span = result_timestamps[-1] - result_timestamps[0]
        final_fps = len(result_timestamps) / final_time_span

        print(f"\nç»“æœç»Ÿè®¡:")
        print(f"  æœ€ç»ˆæ—¶é—´æˆ³é•¿åº¦: {len(result_timestamps)}")
        print(f"  æœ€ç»ˆæ—¶é—´è·¨åº¦: {final_time_span:.3f}s")
        print(f"  æœ€ç»ˆå¸§ç‡: {final_fps:.3f}Hz")
        print(f"  åˆ é™¤å¸§æ•°: {len(main_timestamps) - len(result_timestamps)}")

        # éªŒè¯æœ€ç»ˆæ—¶é—´æˆ³è´¨é‡
        if len(result_timestamps) > 1:
            final_intervals_ms = np.diff(result_timestamps) * 1000
            max_final_interval = np.max(final_intervals_ms)
            avg_final_interval = np.mean(final_intervals_ms)
            std_final_interval = np.std(final_intervals_ms)

            print(f"\næœ€ç»ˆæ—¶é—´æˆ³è´¨é‡:")
            print(f"  æœ€å¤§é—´éš”: {max_final_interval:.1f}ms")
            print(f"  å¹³å‡é—´éš”: {avg_final_interval:.1f}ms")
            print(f"  é—´éš”æ ‡å‡†å·®: {std_final_interval:.1f}ms")

            if max_final_interval <= 40:
                print(f"  âœ“ æ‰€æœ‰é—´éš”éƒ½åœ¨40msä»¥å†…")
            else:
                large_final_intervals = np.sum(final_intervals_ms > 40)
                print(f"  âŒ ä»æœ‰ {large_final_intervals} ä¸ªé—´éš”è¶…è¿‡40ms")

        # éªŒè¯å­æ—¶é—´æˆ³åŒæ­¥æ€§ï¼ˆæŠ½æ ·æ£€æŸ¥ï¼‰
        print(f"\nå­æ—¶é—´æˆ³åŒæ­¥æ€§éªŒè¯ï¼ˆæŠ½æ ·æ£€æŸ¥å‰20å¸§ï¼‰:")
        sync_errors = 0
        check_frames = min(
            20, len(result_timestamps), len(result_modalities["child_sensor"])
        )

        for i in range(check_frames):
            main_ts = result_timestamps[i]
            child_item = result_modalities["child_sensor"][i]
            child_ts = child_item["timestamp"]
            expected_diff = 0.002  # åŸå§‹2mså·®å€¼
            actual_diff = child_ts - main_ts
            diff_error = abs(actual_diff - expected_diff) * 1000

            if diff_error > 0.1:  # 0.1mså®¹å·®
                sync_errors += 1
                print(f"  å¸§{i}: åŒæ­¥åå·® {diff_error:.3f}ms")

                # æ£€æŸ¥æ˜¯å¦æ˜¯é‡æ–°å¹³å‡è¿‡çš„å¸§
                reaveraged = child_item.get("timestamp_reaveraged", False)
                if reaveraged:
                    delta = child_item.get("timestamp_delta", 0)
                    print(f"        (è¯¥å¸§å·²é‡æ–°å¹³å‡, delta: {delta:.6f}s)")

        if sync_errors == 0:
            print(f"  âœ“ æŠ½æ ·æ£€æŸ¥çš„ {check_frames} å¸§éƒ½ä¿æŒäº†2msçš„ç›¸å¯¹å…³ç³»")
        else:
            print(f"  âŒ åœ¨ {check_frames} å¸§ä¸­å‘ç° {sync_errors} ä¸ªåŒæ­¥åå·®")

        # æ˜¾ç¤ºå¤„ç†å‰åçš„å¯¹æ¯”
        print(f"\nå¤„ç†å‰åå¯¹æ¯”:")
        print(
            f"  é•¿åº¦: {len(main_timestamps)} -> {len(result_timestamps)} (-{len(main_timestamps) - len(result_timestamps)})"
        )
        print(f"  å¸§ç‡: {initial_fps:.2f}Hz -> {final_fps:.2f}Hz")
        print(f"  æœ€å¤§é—´éš”: {max_interval_ms:.1f}ms -> {max_final_interval:.1f}ms")

        # æµ‹è¯•ç»“è®º
        length_ok = len(result_timestamps) >= 300  # æœ€ç»ˆé•¿åº¦è¶³å¤Ÿ
        fps_ok = final_fps <= target_fps  # å¸§ç‡è¾¾æ ‡
        interval_ok = max_final_interval <= 40  # é—´éš”è¾¾æ ‡
        sync_ok = sync_errors == 0  # åŒæ­¥è¾¾æ ‡

        print(f"\næµ‹è¯•ç»“è®º:")
        print(
            f"  é•¿åº¦æ£€æŸ¥: {'âœ…' if length_ok else 'âŒ'} ({len(result_timestamps)} >= 300)"
        )
        print(
            f"  å¸§ç‡æ£€æŸ¥: {'âœ…' if fps_ok else 'âŒ'} ({final_fps:.2f} <= {target_fps})"
        )
        print(
            f"  é—´éš”æ£€æŸ¥: {'âœ…' if interval_ok else 'âŒ'} ({max_final_interval:.1f} <= 40ms)"
        )
        print(f"  åŒæ­¥æ£€æŸ¥: {'âœ…' if sync_ok else 'âŒ'}")

        if length_ok and fps_ok and interval_ok and sync_ok:
            print(f"  ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ»‘åŠ¨çª—å£åˆ é™¤+é‡æ–°å¹³å‡ç®—æ³•å·¥ä½œæ­£å¸¸")
        else:
            print(f"  âš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")

        # é¢å¤–æ£€æŸ¥ï¼šéªŒè¯åˆ é™¤+é‡æ–°å¹³å‡çš„æ•ˆæœ
        print(f"\né‡æ–°å¹³å‡æ•ˆæœéªŒè¯:")
        reaveraged_count = 0
        for item in result_modalities["child_sensor"]:
            if item.get("timestamp_reaveraged", False):
                reaveraged_count += 1

        if reaveraged_count > 0:
            print(f"  âœ“ å…±æœ‰ {reaveraged_count} å¸§ç»è¿‡é‡æ–°å¹³å‡å¤„ç†")
            print(
                f"  âœ“ é‡æ–°å¹³å‡æ¯”ä¾‹: {reaveraged_count/len(result_modalities['child_sensor'])*100:.1f}%"
            )
        else:
            print(f"  âš ï¸ æ²¡æœ‰å¸§ç»è¿‡é‡æ–°å¹³å‡å¤„ç†")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥ï¼Œå‡ºç°å¼‚å¸¸:")
        print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"  é”™è¯¯ä¿¡æ¯: {str(e)}")
        import traceback

        traceback.print_exc()
